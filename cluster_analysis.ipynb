{
 "metadata": {
  "name": "",
  "signature": "sha256:fe7f02e1ed859eadcd1d9ad734dbda3862727410eabb5906e761220db5130258"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import nltk\n",
      "import re\n",
      "import os\n",
      "import codecs\n",
      "from sklearn import feature_extraction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filenames = os.listdir('/Users/brandomr/Google Drive/Sites/docs')\n",
      "#gets list of filenames in the document directory\n",
      "\n",
      "len(filenames)\n",
      "#tests how many files are in the docs folder"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "60"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read in the corpora from my local directory\n",
      "\n",
      "corpora = []\n",
      "\n",
      "for i in filenames:\n",
      "    doc = open('/Users/brandomr/Google Drive/Sites/docs/'+ i)\n",
      "    text = doc.read()\n",
      "    #grabs the document as variable text\n",
      "    \n",
      "    text = nltk.clean_html(text)\n",
      "    #strips html formatting\n",
      "    \n",
      "    text = text.replace('&#xa0;', '\\xA0')\n",
      "    text = text.decode('utf-8', 'ignore')\n",
      "    #gets rid of non-break space html and converts to unicode\n",
      "    \n",
      "    corpora.append(text)\n",
      "    #adds to corpora"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generates title list for each item in the corpora. In this case I just generate a number, 0 to 59\n",
      "# you could create a title based on the filename or some element in the text\n",
      "\n",
      "titles = []\n",
      "\n",
      "for i in range(0,len(corpora)):\n",
      "    titles.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load nltk's English stopwords as variable called 'stopwords'\n",
      "\n",
      "stopwords = nltk.corpus.stopwords.words('english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
      "\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "\n",
      "stemmer = SnowballStemmer(\"english\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
      "\n",
      "def tokenize_and_stem(text):\n",
      "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
      "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
      "    filtered_tokens = []\n",
      "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
      "    for token in tokens:\n",
      "        if re.search('[a-zA-Z]', token):\n",
      "            filtered_tokens.append(token)\n",
      "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
      "    return stems"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = feature_extraction.text.CountVectorizer(tokenizer=tokenize_and_stem, \n",
      "                                                     ngram_range=(1, 3), stop_words=stopwords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analyze = vectorizer.build_analyzer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = vectorizer.fit_transform(corpora)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "<60x94483 sparse matrix of type '<type 'numpy.int64'>'\n",
        "\twith 125709 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(vectorizer.get_feature_names())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 118,
       "text": [
        "94483"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print vectorizer.vocabulary_.get('department')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "22910\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "\n",
      "x = TfidfTransformer(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "TfidfTransformer(norm=<60x94483 sparse matrix of type '<type 'numpy.int64'>'\n",
        "\twith 125709 stored elements in Compressed Sparse Row format>,\n",
        "         smooth_idf=True, sublinear_tf=False, use_idf=True)"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenize_and_stem, stop_words=stopwords, ngram_range=(1, 3))\n",
      "\n",
      "tfidf_matrix = tfidf_vectorizer.fit_transform(corpora)\n",
      "\n",
      "print tfidf_matrix.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(60, 94483)\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "\n",
      "sim = 1 - cosine_similarity(tfidf_matrix[1], tfidf_matrix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[  9.47399905e-01,   9.21485110e-15,   9.62871194e-01,\n",
        "          9.48626938e-01,   9.66871009e-01,   7.19944202e-01,\n",
        "          9.01061179e-01,   9.67722669e-01,   8.83485202e-01,\n",
        "          9.75600453e-01,   9.91798641e-01,   8.75833226e-01,\n",
        "          8.92055868e-01,   9.57071979e-01,   9.44574672e-01,\n",
        "          9.52282606e-01,   9.67344734e-01,   9.38000806e-01,\n",
        "          9.57796923e-01,   9.78693744e-01,   8.87432385e-01,\n",
        "          9.78239879e-01,   9.60999361e-01,   9.61220819e-01,\n",
        "          9.51152718e-01,   9.57465240e-01,   9.30628610e-01,\n",
        "          9.82612302e-01,   9.73972829e-01,   8.68732528e-01,\n",
        "          9.56830604e-01,   9.64768940e-01,   9.71697500e-01,\n",
        "          9.65997512e-01,   9.80665414e-01,   9.08171356e-01,\n",
        "          9.48755999e-01,   9.34830956e-01,   9.55327905e-01,\n",
        "          8.97581150e-01,   9.52188963e-01,   9.57330038e-01,\n",
        "          9.36278663e-01,   9.55006313e-01,   9.49072640e-01,\n",
        "          9.62026327e-01,   9.32914165e-01,   9.35515486e-01,\n",
        "          9.20260357e-01,   9.32857750e-01,   9.44211039e-01,\n",
        "          8.98610693e-01,   9.59293485e-01,   9.17778721e-01,\n",
        "          9.42460724e-01,   9.40768829e-01,   9.61761529e-01,\n",
        "          9.39364157e-01,   9.34119500e-01,   9.62469230e-01]])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import euclidean_distances\n",
      "\n",
      "dist = euclidean_distances(tfidf_matrix)\n",
      "\n",
      "dist = 1 - cosine_similarity(tfidf_matrix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "array([[  1.60982339e-14,   9.47399905e-01,   9.84751314e-01, ...,\n",
        "          9.28567588e-01,   9.64787837e-01,   9.72955618e-01],\n",
        "       [  9.47399905e-01,   9.21485110e-15,   9.62871194e-01, ...,\n",
        "          9.39364157e-01,   9.34119500e-01,   9.62469230e-01],\n",
        "       [  9.84751314e-01,   9.62871194e-01,  -8.88178420e-16, ...,\n",
        "          9.79428252e-01,   9.77984967e-01,   9.91854589e-01],\n",
        "       ..., \n",
        "       [  9.28567588e-01,   9.39364157e-01,   9.79428252e-01, ...,\n",
        "          4.44089210e-16,   9.24428532e-01,   9.69528243e-01],\n",
        "       [  9.64787837e-01,   9.34119500e-01,   9.77984967e-01, ...,\n",
        "          9.24428532e-01,  -7.77156117e-15,   9.13364549e-01],\n",
        "       [  9.72955618e-01,   9.62469230e-01,   9.91854589e-01, ...,\n",
        "          9.69528243e-01,   9.13364549e-01,  -1.99840144e-15]])"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#i = 0\n",
      "#for doc in corpora:\n",
      "#    print str(i) + '---' + doc[0:250]\n",
      "#    i+=1\n",
      "#    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###2nd attempt looks like it fits better\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "vectorizer = CountVectorizer(tokenizer=tokenize_and_stem, stop_words=stopwords)\n",
      "\n",
      "dtm = vectorizer.fit_transform(corpora)  # a sparse matrix\n",
      "\n",
      "vocab = vectorizer.get_feature_names()  # a list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(dtm)\n",
      "\n",
      "dtm = dtm.toarray()  # convert to a regular array\n",
      "\n",
      "vocab = np.array(vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dist = euclidean_distances(dtm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dist = 1 - cosine_similarity(dtm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "\n",
      "num_clusters = 8\n",
      "\n",
      "km = KMeans(n_clusters=num_clusters)\n",
      "\n",
      "km = km.fit(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters = km.fit_predict(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters = clusters.tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(clusters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "60"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylab import *\n",
      "\n",
      "cm = get_cmap('gist_rainbow')\n",
      "for i in range(num_clusters):\n",
      "    color = cm(1.*i/num_clusters)  # color will now be an RGBA tuple\n",
      "\n",
      "# or if you really want a generator:\n",
      "cgen = (cm(1.*i/num_clusters) for i in range(num_clusters))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cgen"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "<generator object <genexpr> at 0x11244fcd0>"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "color"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "(0.58930093776641124, 0.0, 1.0, 1.0)"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os  # for os.path.basename\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.manifold import MDS\n",
      "\n",
      "# two components as we're plotting points in a two-dimensional plane\n",
      "# \"precomputed\" because we provide a distance matrix\n",
      "# we will also specify `random_state` so the plot is reproducible.\n",
      "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
      "\n",
      "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
      "\n",
      "xs, ys = pos[:, 0], pos[:, 1]\n",
      "\n",
      "names = titles\n",
      "\n",
      "# color-blind-friendly palette\n",
      "for x, y, cluster in zip(xs, ys, clusters):\n",
      "    plt.scatter(x, y)\n",
      "    plt.text(x, y, cluster) \n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}