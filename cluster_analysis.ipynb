{
 "metadata": {
  "name": "",
  "signature": "sha256:d069535b0dd7659dc77cfecaba7cebe3dcd157082753480f28d1052aaade1c9a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import nltk\n",
      "import re\n",
      "import os\n",
      "import codecs\n",
      "from sklearn import feature_extraction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles = open('title_list.txt').read().split('\\n')\n",
      "titles = titles[:99]\n",
      "\n",
      "links = open('link_list.txt').read().split('\\n')\n",
      "links = links[:99]\n",
      "\n",
      "synopses = open('synopses_list.txt').read().split('\\n BREAKS HERE')\n",
      "synopses = synopses[:99]\n",
      "\n",
      "synopses_clean = []\n",
      "\n",
      "for text in synopses:\n",
      "    text = nltk.clean_html(text)\n",
      "    #strips html formatting\n",
      "    \n",
      "    text = text.replace('\\xef', '')\n",
      "    text = text.replace('&#xa0;', '\\xA0')\n",
      "    text = text.decode('utf-8', 'ignore')\n",
      "    #gets rid of non-break space html and converts to unicode\n",
      "    synopses_clean.append(text)\n",
      "\n",
      "synopses = synopses_clean\n",
      "    \n",
      "    \n",
      "genres = open('genres_list.txt').read().split('\\n')\n",
      "genres = genres[:99]\n",
      "\n",
      "print(str(len(titles)) + ' titles')\n",
      "print(str(len(links)) + ' links')\n",
      "print(str(len(synopses)) + ' synopses')\n",
      "print(str(len(genres)) + ' genres')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "99 titles\n",
        "99 links\n",
        "99 synopses\n",
        "99 genres\n"
       ]
      }
     ],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generates index for each item in the corpora (in this case it's just rank)\n",
      "\n",
      "ranks = []\n",
      "\n",
      "for i in range(0,len(titles)):\n",
      "    ranks.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load nltk's English stopwords as variable called 'stopwords'\n",
      "\n",
      "stopwords = nltk.corpus.stopwords.words('english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
      "\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "\n",
      "stemmer = SnowballStemmer(\"english\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
      "\n",
      "def tokenize_and_stem(text):\n",
      "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
      "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
      "    filtered_tokens = []\n",
      "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
      "    for token in tokens:\n",
      "        if re.search('[a-zA-Z]', token):\n",
      "            filtered_tokens.append(token)\n",
      "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
      "    return stems\n",
      "\n",
      "\n",
      "def tokenize_only(text):\n",
      "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
      "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
      "    filtered_tokens = []\n",
      "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
      "    for token in tokens:\n",
      "        if re.search('[a-zA-Z]', token):\n",
      "            filtered_tokens.append(token)\n",
      "    return filtered_tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "totalvocab_stemmed = []\n",
      "totalvocab_tokenized = []\n",
      "for i in synopses:\n",
      "    allwords_stemmed = tokenize_and_stem(i)\n",
      "    totalvocab_stemmed.extend(allwords_stemmed)\n",
      "    \n",
      "    allwords_tokenized = tokenize_only(i)\n",
      "    totalvocab_tokenized.extend(allwords_tokenized)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(len(totalvocab_stemmed))\n",
      "\n",
      "print(len(totalvocab_tokenized))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "147605\n",
        "147605\n"
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(totalvocab_stemmed[:10], end='')\n",
      "print()\n",
      "print(totalvocab_tokenized[:10], end='')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'in', u'late', u'summer', u'guest', u'are', u'gather', u'for', u'the', u'wed', u'recept']\n",
        "[u'in', u'late', u'summer', u'guests', u'are', u'gathered', u'for', u'the', u'wedding', u'reception']"
       ]
      }
     ],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str(vocab_frame.ix['wed'].values.tolist()[0][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 241,
       "text": [
        "'wedding'"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "tfidf_vectorizer = TfidfVectorizer(max_df=0.3, max_features=10000,\n",
      "                                 min_df=0.1, stop_words='english',\n",
      "                                 use_idf=True, ngram_range=(1,1), tokenizer=tokenize_and_stem)\n",
      "\n",
      "%time tfidf_matrix = tfidf_vectorizer.fit_transform(synopses)\n",
      "\n",
      "print(tfidf_matrix.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 12 s, sys: 103 ms, total: 12.1 s\n",
        "Wall time: 12.1 s\n",
        "(99, 726)\n"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "terms = tfidf_vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn.pipeline import make_pipeline\n",
      "#from sklearn.preprocessing import Normalizer\n",
      "#from sklearn.decomposition import TruncatedSVD\n",
      "\n",
      "#svd = TruncatedSVD(1000)\n",
      "#lsa = make_pipeline(svd, Normalizer(copy=False))\n",
      "\n",
      "#tfidf_matrix.LSA = lsa.fit_transform(tfidf_matrix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import euclidean_distances\n",
      "#dist = euclidean_distances(tfidf_matrix)\n",
      "\n",
      "\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "dist = 1 - cosine_similarity(tfidf_matrix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "vectorizer = CountVectorizer(tokenizer=tokenize_and_stem, stop_words=stopwords)\n",
      "\n",
      "%time dtm = vectorizer.fit_transform(synopses)  # a sparse matrix\n",
      "\n",
      "vocab = vectorizer.get_feature_names()  # a list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 14.7 s, sys: 174 ms, total: 14.9 s\n",
        "Wall time: 16.4 s\n"
       ]
      }
     ],
     "prompt_number": 277
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(dtm)\n",
      "\n",
      "dtm = dtm.toarray()  # convert to a regular array\n",
      "\n",
      "vocab = np.array(vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "\n",
      "#dist = 1- cosine_similarity(dtm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "\n",
      "num_clusters = 8\n",
      "\n",
      "km = KMeans(n_clusters=num_clusters)\n",
      "\n",
      "%time km.fit(tfidf_matrix)\n",
      "\n",
      "clusters = km.labels_.tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 290 ms, sys: 3.39 ms, total: 293 ms\n",
        "Wall time: 292 ms\n"
       ]
      }
     ],
     "prompt_number": 311
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pattern.vector import Document, Model, KMEANS, distance, COSINE\n",
      "\n",
      "synopses_docs = [Document(synopses[i], name=titles[i]) for i in range(len(synopses))]\n",
      "\n",
      "m = Model(documents = synopses_docs)\n",
      "\n",
      "movieclusters = m.cluster(method=KMEANS, k=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in movieclusters:\n",
      "    print(i)\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "films = { 'title': titles, 'rank': ranks, 'synopsis': synopses, 'cluster': clusters, 'genre': genres }\n",
      "\n",
      "frame = pd.DataFrame(films, index = [clusters] , columns = ['rank', 'title', 'cluster', 'genre'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 312
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frame['cluster'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 313,
       "text": [
        "4    24\n",
        "7    18\n",
        "1    18\n",
        "6    16\n",
        "0     8\n",
        "3     7\n",
        "2     5\n",
        "5     3\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 313
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped = frame['rank'].groupby(frame['cluster'])\n",
      "\n",
      "grouped.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 314,
       "text": [
        "cluster\n",
        "0          39.000000\n",
        "1          54.555556\n",
        "2          33.400000\n",
        "3          48.428571\n",
        "4          34.958333\n",
        "5          36.000000\n",
        "6          65.062500\n",
        "7          59.055556\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 314
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frame.ix[4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>rank</th>\n",
        "      <th>title</th>\n",
        "      <th>cluster</th>\n",
        "      <th>genre</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 13</td>\n",
        "      <td>     Sunset Blvd.</td>\n",
        "      <td> 4</td>\n",
        "      <td> [u' Drama', u' Film-Noir']</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 27</td>\n",
        "      <td> Some Like It Hot</td>\n",
        "      <td> 4</td>\n",
        "      <td>               [u' Comedy']</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 68</td>\n",
        "      <td>  Midnight Cowboy</td>\n",
        "      <td> 4</td>\n",
        "      <td>                [u' Drama']</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 285,
       "text": [
        "   rank             title  cluster                       genre\n",
        "4    13      Sunset Blvd.        4  [u' Drama', u' Film-Noir']\n",
        "4    27  Some Like It Hot        4                [u' Comedy']\n",
        "4    68   Midnight Cowboy        4                 [u' Drama']"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "order_centroids.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 265,
       "text": [
        "(8, 4271)"
       ]
      }
     ],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "km.cluster_centers_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 254,
       "text": [
        "(8, 4271)"
       ]
      }
     ],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf_matrix.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 266,
       "text": [
        "(99, 323)"
       ]
      }
     ],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "print(\"Top terms per cluster:\")\n",
      "print()\n",
      "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
      "for i in range(num_clusters):\n",
      "    print(\"Cluster %d words:\" % i, end='')\n",
      "    for ind in order_centroids[i, :30]:\n",
      "        print(' %s' % vocab_frame.ix[terms[ind]].values.tolist()[0][0].encode('utf-8', 'ignore'), end='')\n",
      "    print()\n",
      "    print()\n",
      "    print(\"Cluster %d titles:\" % i, end='')\n",
      "    for title in frame.ix[i]['title'].values.tolist():\n",
      "        print(' %s,' % title, end='')\n",
      "    print()\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top terms per cluster:\n",
        "\n",
        "Cluster 0 words: safely beautiful got relationship"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " inside picture school"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " come become only hanged"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " engaged political old notices"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ready job happen driving"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " bathroom initiate beaten head"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " reaches contained married detectives"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " originally commanding incident\n",
        "\n",
        "Cluster 0 titles: Titanic, Forrest Gump, Chinatown, A Streetcar Named Desire, To Kill a Mockingbird, Ben-Hur, Jaws, The African Queen,\n",
        "\n",
        "Cluster 1 words: any"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " jack seconds henry long"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " grounds redding military audience"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " day grab large captain"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " english reveals authorities noting"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " protection leading recognized knowing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business only floor needed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " inside because assist"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mr. camps\n",
        "\n",
        "Cluster 1 titles: The Shawshank Redemption, One Flew Over the Cuckoo's Nest, Psycho, On the Waterfront, 2001: A Space Odyssey, 12 Angry Men, Unforgiven, Rocky, The Exorcist, Good Will Hunting, Fargo, Giant, American Graffiti, Pulp Fiction, The Maltese Falcon, A Clockwork Orange, Taxi Driver, Double Indemnity,\n",
        "\n",
        "Cluster 2 words: identifies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " saw big brought"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " best pocketed relationship"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " everything assist comments everyone"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " leave dismissing hole rise"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " confessing daughter aims broke"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " alive flower once heavy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " desperate anyone long always"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " investigate ii escape\n",
        "\n",
        "Cluster 2 titles: The Godfather, The Godfather: Part II, E.T. the Extra-Terrestrial, The Deer Hunter, Tootsie,\n",
        "\n",
        "Cluster 3 words: pick"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " instantly minutes arrange any"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " kisses late introduces false"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " set distance prison pool"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " prevent inside far maintains"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " hire relationship considered exploding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mrs. rock letters punishment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " separation house charge piece"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " huge\n",
        "\n",
        "Cluster 3 titles: Citizen Kane, Singin' in the Rain, Amadeus, The Apartment, Mr. Smith Goes to Washington, Annie Hall, Nashville,\n",
        "\n",
        "Cluster 4 words: pocketed anyone causes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " requests best body grows"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " attempt sentences every boat"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " remarks political begs controlled"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rise allow experience"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " returning hearing partner"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " develop fact night horror"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " long love notices responsible"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " black\n",
        "\n",
        "Cluster 4 titles: Schindler's List, Raging Bull, Casablanca, Gone with the Wind, Lawrence of Arabia, The Sound of Music, Star Wars, The Bridge on the River Kwai, Apocalypse Now, Gandhi, The Lord of the Rings: The Return of the King, Gladiator, From Here to Eternity, Saving Private Ryan, Doctor Zhivago, Patton, Braveheart, The Good, the Bad and the Ugly, Butch Cassidy and the Sundance Kid, Platoon, Dances with Wolves, The Pianist, The King's Speech, Rain Man,\n",
        "\n",
        "Cluster 5 words: grave seen gathered"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dances river accuses"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " clearly engaged above"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " calmly drags jump"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " respects grab 's company"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " barely related set horse"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " gone appear happen following"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " determines mentions boys"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " hearing met pushed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Cluster 5 titles: Sunset Blvd., Some Like It Hot, Midnight Cowboy,\n",
        "\n",
        "Cluster 6 words: figure landing saw relationship"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " during boat hand fact"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " potential everyone secretly impressions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " loudly explains kid captured"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " encountered long disappear gang"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " passes home realizing affair"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " great broke mrs."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " packs dismissing english\n",
        "\n",
        "Cluster 6 titles: The Wizard of Oz,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " The Philadelphia Story, An American in Paris, My Fair Lady, High Noon, Goodfellas, All Quiet on the Western Front, City Lights, Terms of Endearment, The Grapes of Wrath, Shane, The Green Mile, Network, Stagecoach, Mutiny on the Bounty, Wuthering Heights,\n",
        "\n",
        "Cluster 7 words: everyone lee favors rushes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " insists following knowing remarks"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " report escorts any aid"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " breaks memorial problem during"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dangerous hotel leading heavy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " confessing afterward house emerged"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " comments assumed inside"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " guarding pistol"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " only\n",
        "\n",
        "Cluster 7 titles: Vertigo, West Side Story, The Silence of the Lambs, It's a Wonderful Life, Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb, Raiders of the Lost Ark, The Best Years of Our Lives, The Treasure of the Sierra Madre, The French Connection, It Happened One Night, A Place in the Sun, Out of Africa, Close Encounters of the Third Kind, The Graduate, Rebel Without a Cause, Rear Window, The Third Man, North by Northwest,\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 315
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "order_centroids.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "(8, 4271)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "(10567,)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os  # for os.path.basename\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "\n",
      "from sklearn.manifold import MDS\n",
      "\n",
      "\n",
      "# two components as we're plotting points in a two-dimensional plane\n",
      "# \"precomputed\" because we provide a distance matrix\n",
      "# we will also specify `random_state` so the plot is reproducible.\n",
      "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
      "\n",
      "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
      "\n",
      "xs, ys = pos[:, 0], pos[:, 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 316
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=titles))\n",
      "\n",
      "groups = df.groupby('label')\n",
      "\n",
      "# Plot\n",
      "fig, ax = plt.subplots(figsize=(17,9))\n",
      "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
      "\n",
      "for name, group in groups:\n",
      "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\n",
      "    ax.set_aspect('auto')\n",
      "ax.legend(numpoints=1)\n",
      "\n",
      "for i in range(len(df)):\n",
      "    ax.text(df.ix[i]['x'], df.ix[i]['y'], df.ix[i]['title'], size=8)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 317
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    }
   ],
   "metadata": {}
  }
 ]
}